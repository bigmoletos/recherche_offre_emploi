#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
API Scraper pour n8n - Module d'Interface REST.

Ce module fournit une API Flask pour exposer les fonctionnalit√©s de scraping
d'offres d'alternance √† n8n et autres syst√®mes d'orchestration.

Fonctionnalit√©s principales :
- API REST avec endpoints s√©curis√©s pour scraping
- Int√©gration compl√®te avec le syst√®me de logging commun
- Configuration hybride avec .env locaux et globaux
- Gestion d'erreurs robuste avec r√©ponses JSON standardis√©es
- Support CORS pour int√©gration n8n/frontend
- Endpoints de monitoring et de sant√©
- Documentation API automatique via docstrings

Architecture :
- Flask comme serveur web l√©ger
- ScraperOffresReelles pour la collecte de donn√©es
- Syst√®me de logging centralis√© avec rotation
- Configuration via variables d'environnement
- R√©ponses JSON structur√©es pour n8n

Usage :
    python api/api_scraper_pour_n8n.py              # D√©marrage standard sur port 5555
    python api/api_scraper_pour_n8n.py --port 3000  # Port personnalis√©
    curl http://localhost:5555/health                # Test de sant√©

Auteur: desmedt.franck@iaproject.fr
Version: 1.0
Date: 03/06/2025
"""

import sys
import os
import argparse
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
from flask import Flask, jsonify, request
from flask_cors import CORS

# Ajouter le module de logging commun
sys.path.insert(
    0, str(Path(__file__).parent.parent.parent / "shared" / "scripts"))
sys.path.insert(
    0, str(Path(__file__).parent.parent.parent / "agent_python" / "src"))

try:
    from logger_config import get_logger, set_global_log_level
    logger = get_logger(__name__, log_file="api_scraper_n8n.log")
except ImportError:
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s')
    logger = logging.getLogger(__name__)
    logger.warning(
        "Module logger_config non disponible, utilisation du logging standard")

# Import des modules de scraping
try:
    from scraper_offres_reelles import ScraperOffresReelles
    logger.info("Module ScraperOffresReelles import√© avec succ√®s")
except ImportError as e:
    logger.error(f"Impossible d'importer ScraperOffresReelles: {e}")
    logger.info("Fonctionnement en mode d√©grad√© avec donn√©es de test")
    ScraperOffresReelles = None


def load_config() -> Dict[str, Any]:
    """
    Charge la configuration selon l'architecture hybride.

    Cette fonction impl√©mente l'ordre de priorit√© des configurations :
    1. Configuration locale agent_n8n/config/.env (priorit√© haute)
    2. Configuration globale .env √† la racine (priorit√© basse)
    3. Variables d'environnement syst√®me (fallback)
    4. Valeurs par d√©faut (dernier recours)

    Returns:
        Dict[str, Any]: Configuration charg√©e avec cl√©s:
            - mistral_api_key: Cl√© API pour l'IA (optionnelle pour l'API)
            - log_level: Niveau de logging
            - api_port: Port d'√©coute de l'API
            - api_host: Host d'√©coute
            - api_debug: Mode debug Flask
            - max_offres_default: Nombre max d'offres par d√©faut
    """
    from dotenv import load_dotenv

    # D√©terminer les chemins des fichiers de configuration (ordre de priorit√©)
    project_root = Path(__file__).parent.parent.parent  # racine du projet
    config_dir = Path(
        __file__).parent.parent / "config"  # config local agent_n8n

    # Fichiers de configuration par ordre de priorit√© (local d'abord, puis global)
    config_files = [
        config_dir / ".env",  # 1. Configuration locale agent_n8n
        project_root / ".env",  # 2. Configuration globale du projet
        config_dir / ".env.example"  # 3. Template de r√©f√©rence
    ]

    # Charger la configuration (premier fichier trouv√©)
    config_loaded = False
    for env_file in config_files:
        if env_file.exists():
            load_dotenv(env_file)
            logger.info(f"Configuration charg√©e depuis {env_file}")
            config_loaded = True
            break

    if not config_loaded:
        logger.warning("Aucun fichier de configuration trouv√©")
        logger.info("Fichiers recherch√©s:")
        for env_file in config_files:
            logger.info(f"  - {env_file}")
        logger.info(
            "Utilisation des variables d'environnement et valeurs par d√©faut")

    # Extraire la configuration avec valeurs par d√©faut
    config = {
        'mistral_api_key': os.getenv('MISTRAL_API_KEY'),
        'log_level': os.getenv('LOG_LEVEL', 'INFO'),
        'api_port': int(os.getenv('API_PORT', 5555)),
        'api_host': os.getenv('API_HOST', '127.0.0.1'),
        'api_debug': os.getenv('API_DEBUG', 'true').lower() == 'true',
        'max_offres_default': int(os.getenv('MAX_OFFRES_DEFAULT', 10)),
        'cors_enabled': os.getenv('CORS_ENABLED', 'true').lower() == 'true',
        'api_secret_key': os.getenv('API_SECRET_KEY'),
        'rate_limit': int(os.getenv('API_RATE_LIMIT', 100))
    }

    # Validation et logging de la configuration
    logger.debug("Configuration API charg√©e:")
    for key, value in config.items():
        if 'api_key' in key.lower() or 'secret' in key.lower():
            if value:
                masked_value = f"{value[:8]}...{value[-4:]}" if len(
                    str(value)) > 12 else "***"
                logger.debug(f"  {key}: {masked_value}")
            else:
                logger.debug(f"  {key}: Non configur√©")
        else:
            logger.debug(f"  {key}: {value}")

    # Avertissements sur la configuration
    if not config['mistral_api_key']:
        logger.info(
            "MISTRAL_API_KEY non configur√©e - l'analyse IA ne sera pas disponible"
        )

    if not config['api_secret_key']:
        logger.warning("API_SECRET_KEY non configur√©e - API non s√©curis√©e")

    return config


class ScraperAPI:
    """
    Classe principale de l'API Flask pour le scraping d'offres.

    Cette classe encapsule toute la logique de l'API REST, incluant
    la configuration, les routes, la gestion d'erreurs et le logging.

    Attributes:
        app (Flask): Instance de l'application Flask
        config (Dict): Configuration charg√©e
        scraper (ScraperOffresReelles): Instance du scraper
    """

    def __init__(self, config: Dict[str, Any]):
        """
        Initialise l'API avec la configuration fournie.

        Args:
            config: Configuration charg√©e via load_config()
        """
        self.config = config
        self.app = Flask(__name__)

        # Configuration CORS si activ√©e
        if config['cors_enabled']:
            CORS(self.app)
            logger.info("CORS activ√© pour int√©gration n8n/frontend")

        # Configuration Flask
        self.app.config['SECRET_KEY'] = config.get('api_secret_key',
                                                   'dev-key-change-me')
        self.app.config['DEBUG'] = config['api_debug']

        # Initialiser le scraper si disponible
        if ScraperOffresReelles:
            try:
                self.scraper = ScraperOffresReelles()
                logger.info("ScraperOffresReelles initialis√© avec succ√®s")
            except Exception as e:
                logger.error(f"Erreur initialisation scraper: {e}")
                self.scraper = None
        else:
            self.scraper = None
            logger.warning("Scraper non disponible - mode test seulement")

        # Enregistrer les routes
        self._register_routes()

        logger.info("API Scraper pour n8n initialis√©e")

    def _register_routes(self):
        """
        Enregistre toutes les routes de l'API.
        """
        # Route de sant√©
        @self.app.route('/health', methods=['GET'])
        def health_check():
            """
            Endpoint de v√©rification de sant√© de l'API.

            Returns:
                JSON: Statut de sant√© avec informations syst√®me
            """
            logger.debug("V√©rification de sant√© demand√©e")

            health_status = {
                "status":
                "healthy",
                "timestamp":
                datetime.now().isoformat(),
                "service":
                "API Scraper Offres pour n8n",
                "version":
                "1.0",
                "scraper_available":
                self.scraper is not None,
                "endpoints": [
                    "/health", "/scrape-offres", "/scrape-pole-emploi",
                    "/test-offres", "/config"
                ]
            }

            return jsonify(health_status)

        # Route principale de scraping
        @self.app.route('/scrape-offres', methods=['POST'])
        def scraper_offres():
            """
            Endpoint principal pour scraper les offres d'alternance.

            Body JSON attendu:
            {
                "termes": ["alternance cybers√©curit√©", "apprentissage s√©curit√©"],
                "max_offres": 10,
                "sources": ["pole_emploi", "apec"]  // optionnel
            }

            Returns:
                JSON: R√©sultats du scraping avec m√©tadonn√©es
            """
            try:
                # R√©cup√©ration et validation des param√®tres
                data = request.get_json() or {}
                termes = data.get('termes', ['alternance cybers√©curit√©'])
                max_offres = min(
                    data.get('max_offres', self.config['max_offres_default']),
                    100)  # Limite s√©curit√©
                sources = data.get('sources', ['pole_emploi', 'apec'])

                logger.info(
                    f"üîç Scraping demand√© - Termes: {termes}, Max: {max_offres}, Sources: {sources}"
                )

                # V√©rifier disponibilit√© du scraper
                if not self.scraper:
                    logger.warning(
                        "Scraper non disponible - retour de donn√©es de test")
                    return self._get_test_response(termes, max_offres)

                # Configuration du scraper
                self.scraper.max_offres_par_site = max_offres
                self.scraper.termes_cybersecurite = termes

                # Collecte des offres
                logger.debug("D√©but de la collecte des offres...")
                offres = self.scraper.collecter_toutes_offres()

                # Pr√©paration de la r√©ponse pour n8n
                response = {
                    "success": True,
                    "timestamp": datetime.now().isoformat(),
                    "request_params": {
                        "termes": termes,
                        "max_offres": max_offres,
                        "sources": sources
                    },
                    "results": {
                        "total_offres": len(offres),
                        "offres": offres
                    },
                    "metadata": {
                        "sources_utilisees": sources,
                        "scraping_duration":
                        "calcul√©_par_scraper",  # TODO: impl√©menter timing
                        "api_version": "1.0"
                    }
                }

                logger.info(
                    f"‚úÖ Scraping termin√© avec succ√®s - {len(offres)} offres trouv√©es"
                )
                return jsonify(response)

            except Exception as e:
                logger.error(f"‚ùå Erreur lors du scraping: {e}")
                logger.exception("D√©tails de l'erreur:")

                error_response = {
                    "success": False,
                    "error": {
                        "message": str(e),
                        "type": type(e).__name__,
                        "timestamp": datetime.now().isoformat()
                    },
                    "results": {
                        "total_offres": 0,
                        "offres": []
                    }
                }

                return jsonify(error_response), 500

        # Route sp√©cifique P√¥le Emploi
        @self.app.route('/scrape-pole-emploi', methods=['POST'])
        def scraper_pole_emploi_seul():
            """
            Endpoint sp√©cifique pour scraper uniquement P√¥le Emploi.

            Body JSON attendu:
            {
                "terme": "alternance cybers√©curit√©",
                "max_offres": 5
            }

            Returns:
                JSON: Offres trouv√©es sur P√¥le Emploi uniquement
            """
            try:
                data = request.get_json() or {}
                terme = data.get('terme', 'alternance cybers√©curit√©')
                max_offres = min(data.get('max_offres', 5),
                                 50)  # Limite pour P√¥le Emploi

                logger.info(
                    f"üîç Scraping P√¥le Emploi exclusivement - Terme: {terme}")

                if not self.scraper:
                    return self._get_test_response([terme], max_offres,
                                                   "pole_emploi")

                # Scraping P√¥le Emploi uniquement
                offres = self.scraper.scraper_pole_emploi(terme)

                response = {
                    "success": True,
                    "source": "pole_emploi",
                    "timestamp": datetime.now().isoformat(),
                    "request_params": {
                        "terme": terme,
                        "max_offres": max_offres
                    },
                    "results": {
                        "total_offres": len(offres),
                        "offres": offres
                    }
                }

                logger.info(
                    f"‚úÖ P√¥le Emploi scraping termin√© - {len(offres)} offres trouv√©es"
                )
                return jsonify(response)

            except Exception as e:
                logger.error(f"‚ùå Erreur P√¥le Emploi scraping: {e}")

                return jsonify({
                    "success": False,
                    "error": {
                        "message": str(e),
                        "type": type(e).__name__,
                        "timestamp": datetime.now().isoformat()
                    },
                    "results": {
                        "total_offres": 0,
                        "offres": []
                    }
                }), 500

        # Route de test
        @self.app.route('/test-offres', methods=['GET'])
        def test_offres():
            """
            Endpoint de test avec offres d'exemple pour d√©veloppement/debug.

            Returns:
                JSON: Offres de test format√©es pour n8n
            """
            logger.debug("Endpoint de test appel√©")
            return self._get_test_response()

        # Route de configuration (pour debug)
        @self.app.route('/config', methods=['GET'])
        def get_config():
            """
            Endpoint pour obtenir la configuration actuelle (debug).

            Returns:
                JSON: Configuration non-sensible de l'API
            """
            logger.debug("Configuration demand√©e")

            safe_config = {
                "api_port": self.config['api_port'],
                "api_host": self.config['api_host'],
                "api_debug": self.config['api_debug'],
                "max_offres_default": self.config['max_offres_default'],
                "cors_enabled": self.config['cors_enabled'],
                "scraper_available": self.scraper is not None,
                "has_mistral_api": bool(self.config['mistral_api_key']),
                "has_api_secret": bool(self.config['api_secret_key'])
            }

            return jsonify(safe_config)

    def _get_test_response(self,
                           termes: List[str] = None,
                           max_offres: int = 2,
                           source: str = "test") -> Dict:
        """
        G√©n√®re une r√©ponse de test avec des offres fictives.

        Args:
            termes: Termes de recherche (pour coh√©rence)
            max_offres: Nombre d'offres √† g√©n√©rer
            source: Source simul√©e

        Returns:
            Dict: R√©ponse JSON avec offres de test
        """
        if termes is None:
            termes = ['alternance cybers√©curit√©']

        offres_test = [{
            "title": "Alternance Cybers√©curit√© - Analyste SOC",
            "company": "TechSecure Corp",
            "location": "Paris (75)",
            "url": "https://candidat.pole-emploi.fr/offres/test1",
            "description":
            "Recherche alternant pour rejoindre notre √©quipe SOC. Formation sur les outils SIEM, analyse de logs et r√©ponse aux incidents.",
            "scraper_source": source,
            "search_term": termes[0] if termes else "test",
            "scraped_at": datetime.now().isoformat(),
            "is_valid": None,
            "ai_response": None
        }, {
            "title": "Apprenti Ing√©nieur S√©curit√© Informatique",
            "company": "SecureIT Solutions",
            "location": "Lyon (69)",
            "url": "https://candidat.pole-emploi.fr/offres/test2",
            "description":
            "Formation en alternance dans le domaine de la s√©curit√© IT. Missions : audit s√©curit√©, tests d'intrusion, gestion des vuln√©rabilit√©s.",
            "scraper_source": source,
            "search_term": termes[0] if termes else "test",
            "scraped_at": datetime.now().isoformat(),
            "is_valid": None,
            "ai_response": None
        }]

        # Limiter au nombre demand√©
        offres_test = offres_test[:max_offres]

        return jsonify({
            "success": True,
            "test_mode": True,
            "timestamp": datetime.now().isoformat(),
            "request_params": {
                "termes": termes,
                "max_offres": max_offres
            },
            "results": {
                "total_offres": len(offres_test),
                "offres": offres_test
            },
            "metadata": {
                "source": source,
                "api_version": "1.0"
            }
        })

    def run(self):
        """
        Lance le serveur Flask avec la configuration charg√©e.
        """
        logger.info("üöÄ D√©marrage de l'API Scraper pour n8n")
        logger.info("üì° Endpoints disponibles:")
        logger.info("   - GET  /health : V√©rification sant√©")
        logger.info(
            "   - POST /scrape-offres : Scraping complet multi-sources")
        logger.info(
            "   - POST /scrape-pole-emploi : P√¥le Emploi exclusivement")
        logger.info("   - GET  /test-offres : Donn√©es de test")
        logger.info("   - GET  /config : Configuration actuelle")
        logger.info(
            f"üåê Serveur accessible sur: http://{self.config['api_host']}:{self.config['api_port']}"
        )

        try:
            logger.debug(f"Tentative de d√©marrage du serveur Flask avec host={self.config['api_host']}, port={self.config['api_port']}, debug={self.config['api_debug']}")
            self.app.run(host=self.config['api_host'],
                         port=self.config['api_port'],
                         debug=self.config['api_debug'],
                         threaded=True)
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du d√©marrage du serveur: {e}")
            raise


def main():
    """
    Fonction principale avec support des arguments CLI.
    """
    parser = argparse.ArgumentParser(
        description="API Flask pour scraping d'offres d'alternance",
        formatter_class=argparse.RawDescriptionHelpFormatter)

    parser.add_argument('--port',
                        type=int,
                        help="Port d'√©coute (override de la config)")

    parser.add_argument('--host',
                        type=str,
                        default='0.0.0.0',
                        help="Host d'√©coute (d√©faut: 0.0.0.0)")

    parser.add_argument('--debug',
                        action='store_true',
                        help="Activer le mode debug Flask")

    parser.add_argument('--log-level',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        help="Niveau de logging (override de la config)")

    args = parser.parse_args()

    # --- D√©but de l'ajout pour diagnostic ---
    print(f"[DIAGNOSTIC] Valeur de args.log_level avant toute configuration: {args.log_level}")
    # --- Fin de l'ajout pour diagnostic ---

    try:
        # Configurer le niveau de logging le plus t√¥t possible
        # pour affecter tous les messages suivants, y compris ceux de load_config.
        initial_log_level = args.log_level or os.getenv('LOG_LEVEL', 'INFO')
        if initial_log_level:
            set_global_log_level(initial_log_level.upper())
            logger.debug(f"Niveau de logger global appliqu√© via set_global_log_level : {initial_log_level.upper()}")
        else:
            # Fallback si initial_log_level est None ou vide, bien que argparse et getenv devraient fournir une valeur.
            logger.warning("Aucun niveau de log initial sp√©cifi√© pour set_global_log_level.")

        # Charger la configuration
        config = load_config()

        # Override avec les arguments CLI
        if args.port:
            config['api_port'] = args.port
        if args.host:
            config['api_host'] = args.host
        if args.debug:
            config['api_debug'] = True

        logger.debug(f"Configuration finale avant initialisation de ScraperAPI : {config}")

        # Cr√©er et lancer l'API
        api = ScraperAPI(config)
        api.run()

    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}")
        logger.exception("D√©tails de l'erreur:")
        sys.exit(1)


if __name__ == '__main__':
    main()
